hjust=-0.2, vjust=5, parse = T) +
theme(legend.position = "none")
p_DW_F_meta <- ggarrange(p_DW_F_meta_SE, p_DW_F_meta_CI)
p_DW_F_meta
pdf(file="DryWeight/p_DW_F_meta.pdf", width=8, height=5)
p_DW_F_meta
invisible(dev.off())
# run the analysis with metagen package
DW_M_metagen <- metagen(data = DW_effects %>% filter(Sex == "M"), TE = Y, seTE = SE, studlab = Study, sm = "SMD", fixed = FALSE, random = TRUE, method.tau = "DL")
DW_M_metagen <- update.meta(DW_M_metagen, subgroup = Population, tau.common = FALSE)
capture.output(summary(DW_M_metagen), file = "DryWeight/DW_M_metagen_sum.txt")
DW_M_metagen
# run the analysis with EK's code for quick plotting
DW_M_meta <- metaAnalysisRandomModel(DW_effects %>% filter(Sex == "M"))
p_DW_M_meta_SE <- DW_M_meta$summary_effects_random %>%
dplyr::select(Population, Mstar, SEMstar) %>%
distinct() %>%
ggplot(aes(x = Mstar, y = 1:length(Population), color = Population)) +
theme_bw() +
geom_point(size = 4, shape = 15) +
geom_errorbarh(aes(xmax = Mstar + SEMstar, xmin = Mstar - SEMstar), height = 0) +
scale_y_continuous(name = "Population", breaks = 1:9,
labels = c("YE","RE","GI","MU","MA","UM","KA","VA","AK")) +
labs(x = "Summary effect", title = "Pop. summary effect with SE") +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank()) +
annotate("text", x = -Inf, y = Inf, label = sprintf("italic(Q) == %.4g", DW_M_meta$Qtest_het$Q),
hjust=-0.2, vjust=3.5, parse = T) +
annotate("text", x = -Inf, y = Inf, label = sprintf("italic(p) == %.4g", DW_M_meta$Qtest_het$p),
hjust=-0.2, vjust=5, parse = T) +
theme(legend.position = "none")
p_DW_M_meta_CI <- DW_M_meta$summary_effects_random %>%
dplyr::select(Population, Mstar, ULMstar, LLMstar) %>%
distinct() %>%
ggplot(aes(x = Mstar, y = 1:length(Population), color = Population)) +
theme_bw() +
geom_point(size = 4, shape = 15) +
geom_errorbarh(aes(xmax = ULMstar, xmin = LLMstar), height = 0) +
scale_y_continuous(name = "Population", breaks = 1:9,
labels = c("YE","RE","GI","MU","MA","UM","KA","VA","AK")) +
labs(x = "Summary effect", title = "Pop. summary effect with 95% CI") +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank()) +
annotate("text", x = -Inf, y = Inf, label = sprintf("italic(Q) == %.4g", DW_M_meta$Qtest_het$Q),
hjust=-0.2, vjust=3.5, parse = T) +
annotate("text", x = -Inf, y = Inf, label = sprintf("italic(p) == %.4g", DW_M_meta$Qtest_het$p),
hjust=-0.2, vjust=5, parse = T) +
theme(legend.position = "none")
p_DW_M_meta <- ggarrange(p_DW_M_meta_SE, p_DW_M_meta_CI)
p_DW_M_meta
pdf(file="DryWeight/p_DW_M_meta.pdf", width=8, height=5)
p_DW_M_meta
invisible(dev.off())
TL_effects <- TL_fitted %>%
dplyr::select(-Value) %>%
mutate(Population = factor(Population, levels = c("YE","RE","GI","MU","MA","UM","KA","VA","AK")),
Lab = as.factor(Lab),
V = SE^2,
Study = paste(Population, Lab, sep = "_")) %>%
relocate(Population, Sex, Lab, Study) %>%
arrange(Population) %>%
dplyr::rename(Y = Estimate)
# run the analysis with metagen package
TL_F_metagen <- metagen(data = TL_effects %>% filter(Sex == "F"), TE = Y, seTE = SE, studlab = Study, sm = "SMD", fixed = FALSE, random = TRUE, method.tau = "DL")
TL_F_metagen <- update.meta(TL_F_metagen, subgroup = Population, tau.common = FALSE)
capture.output(summary(TL_F_metagen), file = "ThoraxLength/TL_F_metagen_sum.txt")
TL_F_metagen
# run the analysis with EK's code for quick plotting
TL_F_meta <- metaAnalysisRandomModel(TL_effects %>% filter(Sex == "F"))
p_TL_F_meta_SE <- TL_F_meta$summary_effects_random %>%
dplyr::select(Population, Mstar, SEMstar) %>%
distinct() %>%
ggplot(aes(x = Mstar, y = 1:length(Population), color = Population)) +
theme_bw() +
geom_point(size = 4, shape = 15) +
geom_errorbarh(aes(xmax = Mstar + SEMstar, xmin = Mstar - SEMstar), height = 0) +
scale_y_continuous(name = "Population", breaks = 1:9,
labels = c("YE","RE","GI","MU","MA","UM","KA","VA","AK")) +
labs(x = "Summary effect", title = "Pop. summary effect with SE") +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank()) +
annotate("text", x = -Inf, y = Inf, label = sprintf("italic(Q) == %.4g", TL_F_meta$Qtest_het$Q),
hjust=-0.2, vjust=3.5, parse = T) +
annotate("text", x = -Inf, y = Inf, label = sprintf("italic(p) == %.4g", TL_F_meta$Qtest_het$p),
hjust=-0.2, vjust=5, parse = T) +
theme(legend.position = "none")
p_TL_F_meta_CI <- TL_F_meta$summary_effects_random %>%
dplyr::select(Population, Mstar, ULMstar, LLMstar) %>%
distinct() %>%
ggplot(aes(x = Mstar, y = 1:length(Population), color = Population)) +
theme_bw() +
geom_point(size = 4, shape = 15) +
geom_errorbarh(aes(xmax = ULMstar, xmin = LLMstar), height = 0) +
scale_y_continuous(name = "Population", breaks = 1:9,
labels = c("YE","RE","GI","MU","MA","UM","KA","VA","AK")) +
labs(x = "Summary effect", title = "Pop. summary effect with 95% CI") +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank()) +
annotate("text", x = -Inf, y = Inf, label = sprintf("italic(Q) == %.4g", TL_F_meta$Qtest_het$Q),
hjust=-0.2, vjust=3.5, parse = T) +
annotate("text", x = -Inf, y = Inf, label = sprintf("italic(p) == %.4g", TL_F_meta$Qtest_het$p),
hjust=-0.2, vjust=5, parse = T) +
theme(legend.position = "none")
p_TL_F_meta <- ggarrange(p_TL_F_meta_SE, p_TL_F_meta_CI)
p_TL_F_meta
pdf(file="ThoraxLength/p_TL_F_meta.pdf", width=8, height=5)
p_TL_F_meta
invisible(dev.off())
# run the analysis with metagen package
TL_M_metagen <- metagen(data = TL_effects %>% filter(Sex == "M"), TE = Y, seTE = SE, studlab = Study, sm = "SMD", fixed = FALSE, random = TRUE, method.tau = "DL")
TL_M_metagen <- update.meta(TL_M_metagen, subgroup = Population, tau.common = FALSE)
capture.output(summary(TL_M_metagen), file = "ThoraxLength/TL_M_metagen_sum.txt")
TL_M_metagen
# run the analysis with EK's code for quick plotting
TL_M_meta <- metaAnalysisRandomModel(TL_effects %>% filter(Sex == "M"))
TL_effects <- TL_fitted %>%
dplyr::select(-Value) %>%
mutate(Population = factor(Population, levels = c("YE","RE","GI","MU","MA","UM","KA","VA","AK")),
Lab = as.factor(Lab),
V = SE^2,
Study = paste(Population, Lab, sep = "_")) %>%
relocate(Population, Sex, Lab, Study) %>%
arrange(Population) %>%
dplyr::rename(Y = Estimate)
(TL_effects %>% filter(Sex == "M")
)
save(TL_effects, file ="TL_effects.RData")
load("/Users/envel.kerdaffrec/Work/UNIFR/GitHub/DrosEU_PhenotypingWG/TL_effects.RData")
load("/Users/envel.kerdaffrec/Work/UNIFR/GitHub/DrosEU_PhenotypingWG/TL_effects.RData")
source("meta_analysis_functions.R")
TL_M_meta <- metaAnalysisRandomModel(TL_effects %>% filter(Sex == "M"))
TL_effects %>% filter(Sex == "F")
TL_effects %>% filter(Sex == "M")
TL_effects
TL_effects
metaAnalysisRandomModel(TL_effects %>% filter(Sex == "F", Supervisor.PI != "Schmidt"))
metaAnalysisRandomModel(TL_effects %>% filter(Sex == "F", Lab != "Schmidt"))
studies.effects = TL_effects %>% filter(Sex == "M")
studies.effects
studies.effects %>%
group_split(Population) %>%
lapply(function(x) T2Comp(Y = x$Y, V = x$V)) %>%
bind_rows() %>%
mutate(Population = unique(studies.effects$Population)) %>%
relocate(Population)
studies.effects %>%
group_split(Population) %>%
lapply(function(x) T2Comp(Y = x$Y, V = x$V))
studies.effects %>%
group_split(Population)
a <- studies.effects %>%
group_split(Population)
a
T2Comp(a[[1]]$Y, a[[1]]$V)
T2Comp(a[[2]]$Y, a[[2]]$V)
T2Comp(a[[3]]$Y, a[[3]]$V)
T2Comp(a[[4]]$Y, a[[4]]$V)
T2Comp(a[[5]]$Y, a[[5]]$V)
T2Comp(a[[6]]$Y, a[[6]]$V)
a[[6]]
a[[2]]
Y = a[[6]]$Y
Y
V = a[[6]]$V
V
W = 1 / V
W
Q = sum(W*Y^2) - sum(W*Y)^2 / sum(W)
df = length(Y) - 1
excess = Q - df
p = pchisq(Q, df = df, lower.tail = FALSE)
C = sum(W) - sum(W^2) / sum(W)
T2 = excess / C
T2
p
Q
excess
df
if (T2 < 0) T2 = 0
T2
T = sqrt(T2)
T
sw1 = sum(W)
sw2 = sum(W^2)
sw3 = sum(W^3)
A = df + 2 * (sw1 - sw2/sw1) * T2 + (sw2 - 2 * (sw3/sw1) + sw2^2/sw1^2) * T2^2
VT2 = 2*(A/C^2)
SET2 = sqrt(VT2)
if (Q > df + 1) B = 0.5 * (log(Q) - log(df)) / (sqrt(2*Q) - sqrt(2*df-1))
if (Q <= df + 1) B = sqrt(1 / (2 * (df-1) * (1 - (1 / (3 * (df-1)^2)))))
L = exp(0.5 * log(Q/df) - 1.96 * B)
U = exp(0.5 * log(Q/df) + 1.96 * B)
LLT2 =  df * (L^2 - 1) / C
LLT2
L
sw1
sw2
sw3
A
VT2
SET2
B
(Q > df + 1)
(Q <= df + 1)
sqrt(1 / (2 * (df-1) * (1 - (1 / (3 * (df-1)^2)))))
Y = a[[2]]$Y
V = a[[2]]$V
W = 1 / V
Q = sum(W*Y^2) - sum(W*Y)^2 / sum(W) # the observed WSS, reflects total dispersion
df = length(Y) - 1 # degrees of freedom, the expected WSS
excess = Q - df # excess variation attributed to differences in true effects
p = pchisq(Q, df = df, lower.tail = FALSE) # test if the heterogeneity is statistically significant
C = sum(W) - sum(W^2) / sum(W) # puts T2 in the same metric as the effect size
T2 = excess / C # estimate of variance between studies, variance of the true effect size
if (T2 < 0) T2 = 0
T = sqrt(T2) # estimate of SD of the true effect size
# below are the confidence intervals for T2
sw1 = sum(W)
sw2 = sum(W^2)
sw3 = sum(W^3)
A = df + 2 * (sw1 - sw2/sw1) * T2 + (sw2 - 2 * (sw3/sw1) + sw2^2/sw1^2) * T2^2
VT2 = 2*(A/C^2)
SET2 = sqrt(VT2)
if (Q > df + 1) B = 0.5 * (log(Q) - log(df)) / (sqrt(2*Q) - sqrt(2*df-1))
if (Q <= df + 1) B = sqrt(1 / (2 * (df-1) * (1 - (1 / (3 * (df-1)^2)))))
B
W = 1 / V
Q = sum(W*Y^2) - sum(W*Y)^2 / sum(W) # the observed WSS, reflects total dispersion
df = length(Y) - 1 # degrees of freedom, the expected WSS
excess = Q - df # excess variation attributed to differences in true effects
p = pchisq(Q, df = df, lower.tail = FALSE) # test if the heterogeneity is statistically significant
C = sum(W) - sum(W^2) / sum(W) # puts T2 in the same metric as the effect size
T2 = excess / C # estimate of variance between studies, variance of the true effect size
if (T2 < 0) T2 = 0
T = sqrt(T2) # estimate of SD of the true effect size
# below are the confidence intervals for T2
sw1 = sum(W)
sw2 = sum(W^2)
sw3 = sum(W^3)
A = df + 2 * (sw1 - sw2/sw1) * T2 + (sw2 - 2 * (sw3/sw1) + sw2^2/sw1^2) * T2^2
VT2 = 2*(A/C^2)
SET2 = sqrt(VT2)
if (Q > df + 1) B = 0.5 * (log(Q) - log(df)) / (sqrt(2*Q) - sqrt(2*df-1))
if (Q <= df + 1) B = sqrt(1 / (2 * (df-1) * (1 - (1 / (3 * (df-1)^2)))))
Q <= df + 1
Q
a[[6]]
a[[2]]
# computes the tau^2 statistics that represents the between-study variance
# also computes different measures of heterogeneity and tests whether heterogeneity is significant
# Y: vector of studies effect size
# W: vector of studies weight
# returns a data.frame with all the computed statistics
T2Comp <- function(Y, V) {
W = 1 / V
Q = sum(W*Y^2) - sum(W*Y)^2 / sum(W) # the observed WSS, reflects total dispersion
df = length(Y) - 1 # degrees of freedom, the expected WSS
excess = Q - df # excess variation attributed to differences in true effects
p = pchisq(Q, df = df, lower.tail = FALSE) # test if the heterogeneity is statistically significant
C = sum(W) - sum(W^2) / sum(W) # puts T2 in the same metric as the effect size
T2 = excess / C # estimate of variance between studies, variance of the true effect size
if (T2 < 0) T2 = 0
T = sqrt(T2) # estimate of SD of the true effect size
# below are the confidence intervals for T2
sw1 = sum(W)
sw2 = sum(W^2)
sw3 = sum(W^3)
A = df + 2 * (sw1 - sw2/sw1) * T2 + (sw2 - 2 * (sw3/sw1) + sw2^2/sw1^2) * T2^2
VT2 = 2*(A/C^2)
SET2 = sqrt(VT2)
if (Q > df + 1) B = 0.5 * (log(Q) - log(df)) / (sqrt(2*Q) - sqrt(2*df-1))
if (Q <= df + 1 & df > 1) B = sqrt(1 / (2 * (df-1) * (1 - (1 / (3 * (df-1)^2)))))
if (Q <= df + 1 & df <= 1) B = 0
L = exp(0.5 * log(Q/df) - 1.96 * B)
U = exp(0.5 * log(Q/df) + 1.96 * B)
LLT2 =  df * (L^2 - 1) / C
if (LLT2 < 0) LLT2 = 0
ULT2 =  df * (U^2 - 1) / C
if (ULT2 < 0) ULT2 = 0
LLT = sqrt(LLT2)
ULT = sqrt(ULT2)
data.frame(Q, df, excess, p, C, T2, T, A, VT2, SET2, B, L, U, LLT2, ULT2, LLT, ULT)
}
V = a[[6]]$V
Y = a[[6]]$Y
W = 1 / V
Q = sum(W*Y^2) - sum(W*Y)^2 / sum(W) # the observed WSS, reflects total dispersion
df = length(Y) - 1 # degrees of freedom, the expected WSS
excess = Q - df # excess variation attributed to differences in true effects
p = pchisq(Q, df = df, lower.tail = FALSE) # test if the heterogeneity is statistically significant
C = sum(W) - sum(W^2) / sum(W) # puts T2 in the same metric as the effect size
T2 = excess / C # estimate of variance between studies, variance of the true effect size
if (T2 < 0) T2 = 0
T = sqrt(T2) # estimate of SD of the true effect size
# below are the confidence intervals for T2
sw1 = sum(W)
sw2 = sum(W^2)
sw3 = sum(W^3)
A = df + 2 * (sw1 - sw2/sw1) * T2 + (sw2 - 2 * (sw3/sw1) + sw2^2/sw1^2) * T2^2
VT2 = 2*(A/C^2)
SET2 = sqrt(VT2)
if (Q > df + 1) B = 0.5 * (log(Q) - log(df)) / (sqrt(2*Q) - sqrt(2*df-1))
if (Q <= df + 1 & df > 1) B = sqrt(1 / (2 * (df-1) * (1 - (1 / (3 * (df-1)^2)))))
if (Q <= df + 1 & df <= 1) B = 0
B
L = exp(0.5 * log(Q/df) - 1.96 * B)
U = exp(0.5 * log(Q/df) + 1.96 * B)
LLT2 =  df * (L^2 - 1) / C
if (LLT2 < 0) LLT2 = 0
ULT2 =  df * (U^2 - 1) / C
if (ULT2 < 0) ULT2 = 0
LLT = sqrt(LLT2)
ULT = sqrt(ULT2)
data.frame(Q, df, excess, p, C, T2, T, A, VT2, SET2, B, L, U, LLT2, ULT2, LLT, ULT)
summmary(TL_M_metagen)
summary(TL_M_metagen)
V = a[[2]]$V
Y = a[[2]]$Y
W = 1 / V
Q = sum(W*Y^2) - sum(W*Y)^2 / sum(W) # the observed WSS, reflects total dispersion
df = length(Y) - 1 # degrees of freedom, the expected WSS
excess = Q - df # excess variation attributed to differences in true effects
p = pchisq(Q, df = df, lower.tail = FALSE) # test if the heterogeneity is statistically significant
C = sum(W) - sum(W^2) / sum(W) # puts T2 in the same metric as the effect size
T2 = excess / C # estimate of variance between studies, variance of the true effect size
if (T2 < 0) T2 = 0
T = sqrt(T2) # estimate of SD of the true effect size
# below are the confidence intervals for T2
sw1 = sum(W)
sw2 = sum(W^2)
sw3 = sum(W^3)
A = df + 2 * (sw1 - sw2/sw1) * T2 + (sw2 - 2 * (sw3/sw1) + sw2^2/sw1^2) * T2^2
VT2 = 2*(A/C^2)
SET2 = sqrt(VT2)
if (Q > df + 1) B = 0.5 * (log(Q) - log(df)) / (sqrt(2*Q) - sqrt(2*df-1))
if (Q <= df + 1 & df > 1) B = sqrt(1 / (2 * (df-1) * (1 - (1 / (3 * (df-1)^2)))))
if (Q <= df + 1 & df <= 1) B = 0
B
L = exp(0.5 * log(Q/df) - 1.96 * B)
U = exp(0.5 * log(Q/df) + 1.96 * B)
LLT2 = df * (L^2 - 1) / C
if (LLT2 < 0) LLT2 = 0
ULT2 = df * (U^2 - 1) / C
if (ULT2 < 0) ULT2 = 0
LLT = sqrt(LLT2)
ULT = sqrt(ULT2)
data.frame(Q, df, excess, p, C, T2, T, A, VT2, SET2, B, L, U, LLT2, ULT2, LLT, ULT)
# run the analysis with EK's code for quick plotting
TL_M_meta <- metaAnalysisRandomModel(TL_effects %>% filter(Sex == "M"))
metaAnalysisRandomModel(TL_effects %>% filter(Sex == "M"))
TL_M_metagen
TL_effects <- TL_fitted %>%
dplyr::select(-Value) %>%
mutate(Population = factor(Population, levels = c("YE","RE","GI","MU","MA","UM","KA","VA","AK")),
Lab = as.factor(Lab),
V = SE^2,
Study = paste(Population, Lab, sep = "_")) %>%
relocate(Population, Sex, Lab, Study) %>%
arrange(Population) %>%
dplyr::rename(Y = Estimate)
# run the analysis with metagen package
TL_F_metagen <- metagen(data = TL_effects %>% filter(Sex == "F"), TE = Y, seTE = SE, studlab = Study, sm = "SMD", fixed = FALSE, random = TRUE, method.tau = "DL")
TL_F_metagen <- update.meta(TL_F_metagen, subgroup = Population, tau.common = FALSE)
capture.output(summary(TL_F_metagen), file = "ThoraxLength/TL_F_metagen_sum.txt")
TL_F_metagen
# run the analysis with EK's code for quick plotting
TL_F_meta <- metaAnalysisRandomModel(TL_effects %>% filter(Sex == "F"))
p_TL_F_meta_SE <- TL_F_meta$summary_effects_random %>%
dplyr::select(Population, Mstar, SEMstar) %>%
distinct() %>%
ggplot(aes(x = Mstar, y = 1:length(Population), color = Population)) +
theme_bw() +
geom_point(size = 4, shape = 15) +
geom_errorbarh(aes(xmax = Mstar + SEMstar, xmin = Mstar - SEMstar), height = 0) +
scale_y_continuous(name = "Population", breaks = 1:9,
labels = c("YE","RE","GI","MU","MA","UM","KA","VA","AK")) +
labs(x = "Summary effect", title = "Pop. summary effect with SE") +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank()) +
annotate("text", x = -Inf, y = Inf, label = sprintf("italic(Q) == %.4g", TL_F_meta$Qtest_het$Q),
hjust=-0.2, vjust=3.5, parse = T) +
annotate("text", x = -Inf, y = Inf, label = sprintf("italic(p) == %.4g", TL_F_meta$Qtest_het$p),
hjust=-0.2, vjust=5, parse = T) +
theme(legend.position = "none")
p_TL_F_meta_CI <- TL_F_meta$summary_effects_random %>%
dplyr::select(Population, Mstar, ULMstar, LLMstar) %>%
distinct() %>%
ggplot(aes(x = Mstar, y = 1:length(Population), color = Population)) +
theme_bw() +
geom_point(size = 4, shape = 15) +
geom_errorbarh(aes(xmax = ULMstar, xmin = LLMstar), height = 0) +
scale_y_continuous(name = "Population", breaks = 1:9,
labels = c("YE","RE","GI","MU","MA","UM","KA","VA","AK")) +
labs(x = "Summary effect", title = "Pop. summary effect with 95% CI") +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank()) +
annotate("text", x = -Inf, y = Inf, label = sprintf("italic(Q) == %.4g", TL_F_meta$Qtest_het$Q),
hjust=-0.2, vjust=3.5, parse = T) +
annotate("text", x = -Inf, y = Inf, label = sprintf("italic(p) == %.4g", TL_F_meta$Qtest_het$p),
hjust=-0.2, vjust=5, parse = T) +
theme(legend.position = "none")
p_TL_F_meta <- ggarrange(p_TL_F_meta_SE, p_TL_F_meta_CI)
p_TL_F_meta
pdf(file="ThoraxLength/p_TL_F_meta.pdf", width=8, height=5)
p_TL_F_meta
invisible(dev.off())
# run the analysis with metagen package
TL_M_metagen <- metagen(data = TL_effects %>% filter(Sex == "M"), TE = Y, seTE = SE, studlab = Study, sm = "SMD", fixed = FALSE, random = TRUE, method.tau = "DL")
TL_M_metagen <- update.meta(TL_M_metagen, subgroup = Population, tau.common = FALSE)
capture.output(summary(TL_M_metagen), file = "ThoraxLength/TL_M_metagen_sum.txt")
TL_M_metagen
# run the analysis with EK's code for quick plotting
TL_M_meta <- metaAnalysisRandomModel(TL_effects %>% filter(Sex == "M"))
p_TL_M_meta_SE <- TL_M_meta$summary_effects_random %>%
dplyr::select(Population, Mstar, SEMstar) %>%
distinct() %>%
ggplot(aes(x = Mstar, y = 1:length(Population), color = Population)) +
theme_bw() +
geom_point(size = 4, shape = 15) +
geom_errorbarh(aes(xmax = Mstar + SEMstar, xmin = Mstar - SEMstar), height = 0) +
scale_y_continuous(name = "Population", breaks = 1:9,
labels = c("YE","RE","GI","MU","MA","UM","KA","VA","AK")) +
labs(x = "Summary effect", title = "Pop. summary effect with SE") +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank()) +
annotate("text", x = -Inf, y = Inf, label = sprintf("italic(Q) == %.4g", TL_M_meta$Qtest_het$Q),
hjust=-0.2, vjust=3.5, parse = T) +
annotate("text", x = -Inf, y = Inf, label = sprintf("italic(p) == %.4g", TL_M_meta$Qtest_het$p),
hjust=-0.2, vjust=5, parse = T) +
theme(legend.position = "none")
p_TL_M_meta_CI <- TL_M_meta$summary_effects_random %>%
dplyr::select(Population, Mstar, ULMstar, LLMstar) %>%
distinct() %>%
ggplot(aes(x = Mstar, y = 1:length(Population), color = Population)) +
theme_bw() +
geom_point(size = 4, shape = 15) +
geom_errorbarh(aes(xmax = ULMstar, xmin = LLMstar), height = 0) +
scale_y_continuous(name = "Population", breaks = 1:9,
labels = c("YE","RE","GI","MU","MA","UM","KA","VA","AK")) +
labs(x = "Summary effect", title = "Pop. summary effect with 95% CI") +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank()) +
annotate("text", x = -Inf, y = Inf, label = sprintf("italic(Q) == %.4g", TL_M_meta$Qtest_het$Q),
hjust=-0.2, vjust=3.5, parse = T) +
annotate("text", x = -Inf, y = Inf, label = sprintf("italic(p) == %.4g", TL_M_meta$Qtest_het$p),
hjust=-0.2, vjust=5, parse = T) +
theme(legend.position = "none")
p_TL_M_meta <- ggarrange(p_TL_M_meta_SE, p_TL_M_meta_CI)
p_TL_M_meta
pdf(file="ThoraxLength/p_TL_M_meta.pdf", width=8, height=5)
p_TL_M_meta
invisible(dev.off())
WA_effects <- WA_fitted %>%
dplyr::select(-Value) %>%
mutate(Population = factor(Population, levels = c("YE","RE","GI","MU","MA","UM","KA","VA","AK")),
Lab = as.factor(Lab),
V = SE^2,
Study = paste(Population, Lab, sep = "_")) %>%
relocate(Population, Sex, Lab, Study) %>%
arrange(Population) %>%
dplyr::rename(Y = Estimate)
getwd()
CCRT_F_coxme_Vieira_sum <- read.delim("SurvivalAnalyses/CCRT_F_coxme_Vieira_sum.txt")
CCRT_F_coxme_Vieira_sum
CCRT_F_coxme_Vieira_sum <- load("SurvivalAnalyses/CCRT_F_coxme_Vieira_sum.txt")
CCRT_F_coxme_Vieira_sum <- read.table("SurvivalAnalyses/CCRT_F_coxme_Vieira_sum.txt")
load("/Users/durmazm/Documents/GitHub/DrosEU_PhenotypingWG/Diapause/d_Dia_trans_for_esra.RData")
View(d_Dia_trans_for_esra)
View(d_Dia_trans_for_esra)
#{r d_Pgm}
d_Pgm <- read.csv("MasterSheets_Oct21_git/PGM_MasterSheet_Jan22.csv")
#{r}
str(d_Pgm)
#{r}
d_Pgm$Supervisor.PI <- as.factor(d_Pgm$Supervisor.PI)
d_Pgm$Diet <- as.factor(d_Pgm$Diet)
d_Pgm$Batch <- as.factor(d_Pgm$Batch)
d_Pgm$Population_Lat <- factor(d_Pgm$Population, levels= c("YE","RE","GI","MU","MA","UM","KA","VA","AK"))
d_Pgm$Population_Lon <- factor(d_Pgm$Population, levels= c("RE","GI","KA","MU","MA","AK","UM","YE","VA"))
d_Pgm$Population_Alt <- factor(d_Pgm$Population, levels= c("KA","AK","GI","RE","UM","VA","MU","MA","YE"))
d_Pgm$Line <- as.factor(d_Pgm$Line)
d_Pgm$AreaT4 <- as.numeric(d_Pgm$AreaT4)
d_Pgm$AreaT5 <- as.numeric(d_Pgm$AreaT5)
d_Pgm$AreaT6 <- as.numeric(d_Pgm$AreaT6)
d_Pgm$PercT4 <- as.numeric(d_Pgm$PercT4)
d_Pgm$PercT5 <- as.numeric(d_Pgm$PercT5)
d_Pgm$PercT6 <- as.numeric(d_Pgm$PercT6)
d_Pgm$TotalArea <- as.numeric(d_Pgm$TotalArea)
d_Pgm$TotalBlack <- as.numeric(d_Pgm$TotalBlack)
d_Pgm$Latitude <- as.numeric(d_Pgm$Latitude)
d_Pgm$Longitude <- as.numeric(d_Pgm$Latitude)
d_Pgm$Altitude <- as.numeric(d_Pgm$Altitude)
#{r}
str(d_Pgm)
#{r d_Pgm2}
d_Pgm2 <- read.csv("MasterSheets_Oct21_git/PGM2_MasterSheet_Oct21.csv")
#{r}
str(d_Pgm2)
#{r}
d_Pgm2$Supervisor.PI <- as.factor(d_Pgm2$Supervisor.PI)
d_Pgm2$Diet <- as.factor(d_Pgm2$Diet)
d_Pgm2$Batch <- as.factor(d_Pgm2$Batch)
d_Pgm2$Population_Lat <- factor(d_Pgm2$Population, levels= c("YE","RE","GI","MU","MA","UM","KA","VA","AK"))
d_Pgm2$Population_Lon <- factor(d_Pgm2$Population, levels= c("RE","GI","KA","MU","MA","AK","UM","YE","VA"))
d_Pgm2$Population_Alt <- factor(d_Pgm2$Population, levels= c("KA","AK","GI","RE","UM","VA","MU","MA","YE"))
d_Pgm2$Line <- as.factor(d_Pgm2$Line)
d_Pgm2$Tergite8 <- as.numeric(d_Pgm2$Tergite8)
d_Pgm2$Tergite9 <- as.numeric(d_Pgm2$Tergite9)
d_Pgm2$Tergite10 <- as.numeric(d_Pgm2$Tergite10)
d_Pgm2$Total <- as.numeric(d_Pgm2$Total)
#{r}
str(d_Pgm2)
